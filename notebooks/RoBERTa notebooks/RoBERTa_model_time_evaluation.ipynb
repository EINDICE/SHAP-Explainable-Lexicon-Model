{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tMjZzmB6PTm"
      },
      "source": [
        "# User Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twAm5QQn6PJG"
      },
      "outputs": [],
      "source": [
        "# enter the location of the sentiment clasification model\n",
        "model_loc = '/content/drive/MyDrive/roberta_model'\n",
        "\n",
        "# enter the location of the tokenizer\n",
        "tokenizer_loc = '/content/drive/MyDrive/roberta_tokenizer'\n",
        "\n",
        "# enter the location of all evaluation datasets (please make sure that there are only evaluation files in the folder)\n",
        "eval_datasets_folder_loc = '/content/drive/MyDrive/datasets/evaluation datasets'\n",
        "\n",
        "# please enter the runtime type: CPU or GPU\n",
        "runtime_type = 'CPU'\n",
        "\n",
        "# enter the folder location where the result dataset should be saved\n",
        "time_evaluation_df_loc = '/content/drive/MyDrive/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time Evaluation"
      ],
      "metadata": {
        "id": "PJon-ZctHPqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "q2QZm7tvYvI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import pandas as pd\n",
        "\n",
        "def extract_file_name(file_loc):\n",
        "  return file_loc.split('/')[-1].split('.')[0]\n",
        "\n",
        "def extract_datasets_map(datasets_location):\n",
        "  location = datasets_location if datasets_location[-1] == '/' else f'{datasets_location}/'\n",
        "  files_locations = [join(location, f) for f in listdir(location) if isfile(join(location, f))]\n",
        "\n",
        "  print(f'Reading datasets from: {location} ...')\n",
        "\n",
        "  assert files_locations != 0, 'No files found in the provided location'\n",
        "\n",
        "  datasets_map = {}\n",
        "  for f in files_locations:\n",
        "    print(f'Reading dataset: {f} ...')\n",
        "    dataset = pd.read_csv(f)\n",
        "    datasets_map[extract_file_name(f)] = dataset\n",
        "\n",
        "  print(f'Reading datasets successfully finished ...')\n",
        "\n",
        "  return datasets_map\n",
        "\n",
        "\n",
        "def create_results_folder(loc):\n",
        "  parent_location = os.path.abspath(os.path.join(loc, os.pardir))\n",
        "  mod_location = parent_location if parent_location[-1] == '/' else f'{parent_location}/'\n",
        "\n",
        "  results_location = f'{mod_location}results'\n",
        "\n",
        "  if not os.path.exists(results_location):\n",
        "    os.makedirs(results_location)\n",
        "\n",
        "  print(f'Created results dataset on location: {results_location} ...')\n",
        "\n",
        "  return results_location"
      ],
      "metadata": {
        "id": "uqof3BUAPsxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "# loading model and tokenizer\n",
        "if runtime_type == 'GPU':\n",
        "  model = torch.load(model_loc)\n",
        "  tokenizer = torch.load(tokenizer_loc)\n",
        "else:\n",
        "  model = torch.load(model_loc, map_location=torch.device('cpu'))\n",
        "  tokenizer = torch.load(tokenizer_loc, map_location=torch.device('cpu'))"
      ],
      "metadata": {
        "id": "ne-34LDCEooA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import timeit\n",
        "\n",
        "def calc_time():\n",
        "  return md(sentences)\n",
        "\n",
        "eval_datasets_map = extract_datasets_map(eval_datasets_folder_loc)\n",
        "\n",
        "if runtime_type == 'GPU':\n",
        "  md = pipeline('sentiment-analysis', model, tokenizer=tokenizer, return_all_scores=True, device=0)\n",
        "else:\n",
        "  md = pipeline('sentiment-analysis', model, tokenizer=tokenizer, return_all_scores=True)\n",
        "md.function_to_apply = 'sigmoid'\n",
        "\n",
        "rows = []\n",
        "\n",
        "for eval_name in eval_datasets_map:\n",
        "  eval_df = eval_datasets_map[eval_name]\n",
        "  sentences = list(eval_df.text.values)\n",
        "  labels = eval_df.sentiment.values\n",
        "\n",
        "  num_times = 10\n",
        "  execution_time = timeit.timeit(calc_time, number=num_times)\n",
        "  duration = execution_time / num_times\n",
        "\n",
        "  sent_num = len(sentences)\n",
        "  new_row = [f'RoBERTa {runtime_type}', eval_name, sent_num, duration]\n",
        "  rows.append(new_row)\n",
        "\n",
        "  cols = ['Source', 'Eval Dataset', 'Sentences No.', 'Time in s']\n",
        "\n",
        "  transformer_time_df = pd.DataFrame(rows, columns = cols)\n",
        "\n",
        "  transformer_time_df_loc = f'{time_evaluation_df_loc}/{runtime_type}_roberta_model_time_evaluation_average_10_times.csv'\n",
        "  transformer_time_df.to_csv(transformer_time_df_loc, index=False)"
      ],
      "metadata": {
        "id": "D-JXEpAyJxaa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "mount_file_id": "1wmiBTulZdZq_0AnoCVAcKLRMrQZ_8b34",
      "authorship_tag": "ABX9TyMbA4LTE/u1ugynmHZh33pT"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
