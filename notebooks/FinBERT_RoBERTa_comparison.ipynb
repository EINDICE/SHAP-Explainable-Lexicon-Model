{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hristijanpeshov/SHAP-Explainable-Lexicon-Model/blob/master/FinBERT_RoBERTa_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User Input"
      ],
      "metadata": {
        "id": "hOhTgMh6Ep-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# enter the location of the summary_df.csv file for each of the lexicons\n",
        "# this file is located in the results folder of the appropriate lexicon\n",
        "\n",
        "# enter location of the RoBERTa lexicons (please make sure that there are only lexicons files in the folder)\n",
        "roberta_lexicons_results_loc = {\n",
        "    'nasdaq': '/content/drive/MyDrive/nasdaq/concatenated datasets/results/summary_df.csv',\n",
        "    'fpb': '/content/drive/MyDrive/fpb/concatenated datasets/results/summary_df.csv',\n",
        "    'sentfin': '/content/drive/MyDrive/sentfin/concatenated datasets/results/summary_df.csv'\n",
        "}\n",
        "\n",
        "# enter location of the FinBERT lexicons (please make sure that there are only lexicons files in the folder)\n",
        "finbert_lexicons_results_loc = {\n",
        "    'nasdaq': '/content/drive/MyDrive/finbert process/nasdaq/concatenated datasets/results/summary_df.csv',\n",
        "    'fpb': '/content/drive/MyDrive/finbert process/fpb/concatenated datasets/results/summary_df.csv',\n",
        "    'sentfin': '/content/drive/MyDrive/finbert process/sentfin/concatenated datasets/results/summary_df.csv'\n",
        "}"
      ],
      "metadata": {
        "id": "L9rEx_iOEtBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FinBERT - RoBERTa Comparison"
      ],
      "metadata": {
        "id": "1bM7N2QyFAzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metric_values(df, eval_df, normalized, metric):\n",
        "  # the different types of evaluation\n",
        "  word_sources = ['LMD', 'OUR', 'OUR + LMD', 'LMD on LMD', 'OUR on LMD', 'OUR + LMD on LMD']\n",
        "  all_metric_values = []\n",
        "\n",
        "  for ws in word_sources:\n",
        "    eval_df_mask = df['Evaluation Dataset'] == eval_df\n",
        "    lexicon_normalized_mask = df['Lexicon Normalized'] == normalized\n",
        "    word_source_mask = df['Words Source'] == ws\n",
        "\n",
        "    combined_mask = eval_df_mask & lexicon_normalized_mask & word_source_mask\n",
        "\n",
        "    # extracting the selected metric values for all lexicon sources\n",
        "    metric_value = df[combined_mask][metric].values[0]\n",
        "\n",
        "    all_metric_values.append(metric_value)\n",
        "\n",
        "  return all_metric_values\n",
        "\n",
        "def is_coef_irregular(coefs):\n",
        "  return len(coefs) != 1 and '\\\\' not in coefs\n",
        "\n",
        "def get_coefs(df):\n",
        "  c1 = df['C1'].unique()\n",
        "  c2 = df['C2'].unique()\n",
        "  c3 = df['C3'].unique()\n",
        "  c4 = df['C4'].unique()\n",
        "\n",
        "  if is_coef_irregular(c1) or is_coef_irregular(c2) or is_coef_irregular(c3) or is_coef_irregular(c4):\n",
        "    print('Missing values for coefficients')\n",
        "\n",
        "  return [c1[0], c2[0], c3[0], c4[0]]\n",
        "\n",
        "def create_summary_dataset(df, metric):\n",
        "  # source lexicon name\n",
        "  source_df = df['Lexicon Source'].unique()[0]\n",
        "\n",
        "  # evaluation dataset names\n",
        "  eval_dfs = df['Evaluation Dataset'].unique()\n",
        "  # is the lexicon normalized\n",
        "  normalized = True\n",
        "  # extracting the coefficients\n",
        "  coefs = get_coefs(df)\n",
        "  # the decision maker is average_shap_values\n",
        "  decision_maker = 'average_shap_values'\n",
        "\n",
        "  summary_df_values = []\n",
        "\n",
        "  # for the selected source lexicon and each of evaluation datasets, extract the metric value\n",
        "  for ed in eval_dfs:\n",
        "\n",
        "    for n in [normalized, not normalized]:\n",
        "      metric_values = get_metric_values(df, ed, n, metric)\n",
        "      row_value = [source_df, n, ed, decision_maker] + coefs + metric_values\n",
        "      summary_df_values.append(row_value)\n",
        "\n",
        "  cols = ['Lexicon Source', 'Lexicon Normalized', 'Evaluation Dataset', 'Decision Maker', 'C1', 'C2', 'C3', 'C4',\n",
        "          'LM', 'XLex', 'XLex + LM', 'LM on LM', 'XLex on LM', 'XLex + LM on LM']\n",
        "\n",
        "  return pd.DataFrame(summary_df_values, columns = cols)"
      ],
      "metadata": {
        "id": "fbI299dVIuZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_lexicons(lexicon_map):\n",
        "  lexicon_dfs = []\n",
        "  for lexicon_name in lexicon_map:\n",
        "    loc = lexicon_map[lexicon_name]\n",
        "    lex = pd.read_csv(loc)\n",
        "\n",
        "    lex_source = lex['Lexicon Source'].values[0]\n",
        "    if lex_source == 'fpb':\n",
        "      lex['Lexicon Source'] = 'financial_phrase_bank'\n",
        "    elif lex_source == 'sentfin':\n",
        "      lex['Lexicon Source'] = 'fiqa_fpb_sentfin_neutral'\n",
        "\n",
        "    lexicon_dfs.append(lex)\n",
        "\n",
        "  return lexicon_dfs\n",
        "\n",
        "def create_metric_df(lexicon_maps):\n",
        "  model_map = {}\n",
        "  for lm in lexicon_maps:\n",
        "    metrics = ['Accuracy', 'F1', 'MCC']\n",
        "    sources = load_lexicons(lexicon_maps[lm])\n",
        "    metric_dfs_map = {}\n",
        "\n",
        "    # for each metric values, extract the results for the source lexicons\n",
        "    for metric in metrics:\n",
        "      df = pd.DataFrame()\n",
        "\n",
        "      for source in sources:\n",
        "        summary_dataset = create_summary_dataset(source, metric)\n",
        "        df = pd.concat([df, summary_dataset], ignore_index = True)\n",
        "\n",
        "      metric_dfs_map[metric] = df\n",
        "\n",
        "    model_map[lm] = metric_dfs_map\n",
        "\n",
        "  return model_map"
      ],
      "metadata": {
        "id": "S835PLIUyzRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def absolute_metric_increase(df, first_col, second_col):\n",
        "  new_value = df[first_col].mean()\n",
        "  old_value = df[second_col].mean()\n",
        "\n",
        "  return new_value - old_value\n",
        "\n",
        "def calc_incr(df, combination):\n",
        "  first_col = combination[0]\n",
        "  second_col = combination[1]\n",
        "  print(f'{first_col}, {second_col}')\n",
        "\n",
        "  absolute_increase = absolute_metric_increase(df, first_col, second_col)\n",
        "  print(absolute_increase)\n",
        "\n",
        "  return absolute_increase\n",
        "\n",
        "def calc_for_metric(df, metric, combinations):\n",
        "  absolute_increases = []\n",
        "\n",
        "  print('Difference between the two columns (absolute difference):')\n",
        "  for comb in combinations:\n",
        "    absolute_increases.append(calc_incr(df, comb))\n",
        "  print()\n",
        "\n",
        "  return absolute_increases\n",
        "\n",
        "def calc_difference(metrics, models_lexicons_res_map):\n",
        "  combinations = [['XLex + LM', 'LM'], ['XLex', 'LM']]\n",
        "\n",
        "  for metric in metrics:\n",
        "    print('Calculations for metric: ', metric)\n",
        "    print()\n",
        "    models_absolute_increases = []\n",
        "    for name in models_lexicons_res_map:\n",
        "      lex_map = models_lexicons_res_map[name]\n",
        "      lex_df = lex_map[metric]\n",
        "      print(name)\n",
        "      models_absolute_increases.append(calc_for_metric(lex_df, metric, combinations))\n",
        "\n",
        "    print()\n",
        "\n",
        "    roberta_abs_increases, finbert_abs_increases = models_absolute_increases\n",
        "    roberta_xlex_lm_abs_inc, roberta_xlex_abs_inc = roberta_abs_increases\n",
        "    finbert_xlex_lm_abs_inc, finbert_xlex_abs_inc = finbert_abs_increases\n",
        "\n",
        "    print('Difference: FinBERT - RoBERTa')\n",
        "    print(', '.join(combinations[0]))\n",
        "    print(finbert_xlex_lm_abs_inc - roberta_xlex_lm_abs_inc)\n",
        "    print()\n",
        "\n",
        "    print('Difference: FinBERT - RoBERTa')\n",
        "    print(', '.join(combinations[1]))\n",
        "    print(finbert_xlex_abs_inc - roberta_xlex_abs_inc)\n",
        "\n",
        "    print()\n",
        "    print()\n",
        "    print()"
      ],
      "metadata": {
        "id": "F1z5qi9_ypA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_lexicons_results_map = {\n",
        "    'RoBERTa': roberta_lexicons_results_loc,\n",
        "    'FinBERT': finbert_lexicons_results_loc\n",
        "}\n",
        "\n",
        "models_lexicons_results_dfs = create_metric_df(models_lexicons_results_map)\n",
        "\n",
        "calc_difference(['Accuracy', 'F1', 'MCC'], models_lexicons_results_dfs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8e4ad00-297c-4c3a-ca54-465c2a26f2bb",
        "id": "X6HJzzHxypA4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculations for metric:  Accuracy\n",
            "\n",
            "RoBERTa\n",
            "Difference between the two columns (absolute difference):\n",
            "XLex + LM, LM\n",
            "0.42334428404339486\n",
            "XLex, LM\n",
            "0.40972001522165913\n",
            "\n",
            "FinBERT\n",
            "Difference between the two columns (absolute difference):\n",
            "XLex + LM, LM\n",
            "0.43431836577490374\n",
            "XLex, LM\n",
            "0.41118192332613007\n",
            "\n",
            "\n",
            "Difference: FinBERT - RoBERTa\n",
            "XLex + LM, LM\n",
            "0.010974081731508878\n",
            "\n",
            "Difference: FinBERT - RoBERTa\n",
            "XLex, LM\n",
            "0.0014619081044709437\n",
            "\n",
            "\n",
            "\n",
            "Calculations for metric:  F1\n",
            "\n",
            "RoBERTa\n",
            "Difference between the two columns (absolute difference):\n",
            "XLex + LM, LM\n",
            "0.276409039748679\n",
            "XLex, LM\n",
            "0.18824323572215362\n",
            "\n",
            "FinBERT\n",
            "Difference between the two columns (absolute difference):\n",
            "XLex + LM, LM\n",
            "0.26955628472774623\n",
            "XLex, LM\n",
            "0.22446185739717145\n",
            "\n",
            "\n",
            "Difference: FinBERT - RoBERTa\n",
            "XLex + LM, LM\n",
            "-0.006852755020932744\n",
            "\n",
            "Difference: FinBERT - RoBERTa\n",
            "XLex, LM\n",
            "0.036218621675017826\n",
            "\n",
            "\n",
            "\n",
            "Calculations for metric:  MCC\n",
            "\n",
            "RoBERTa\n",
            "Difference between the two columns (absolute difference):\n",
            "XLex + LM, LM\n",
            "0.19599610724447994\n",
            "XLex, LM\n",
            "0.12120549223824309\n",
            "\n",
            "FinBERT\n",
            "Difference between the two columns (absolute difference):\n",
            "XLex + LM, LM\n",
            "0.25427234764504225\n",
            "XLex, LM\n",
            "0.19766728730411107\n",
            "\n",
            "\n",
            "Difference: FinBERT - RoBERTa\n",
            "XLex + LM, LM\n",
            "0.05827624040056231\n",
            "\n",
            "Difference: FinBERT - RoBERTa\n",
            "XLex, LM\n",
            "0.07646179506586798\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "mount_file_id": "1QyEdx2T0cIRfrqShgkCQF4_bf5I3-D2A",
      "authorship_tag": "ABX9TyOZ69LO4zxHEWscN5pA3T5O",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}